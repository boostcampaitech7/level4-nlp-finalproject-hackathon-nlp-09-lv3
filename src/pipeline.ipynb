{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "생성된 DB가 있어 로드합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/clone/src/modules/DB/chromadb_storing.py:127: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  self.db = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'chrdb.db' loaded from 'modules/DB/Eval_DB_NaverCloudEmb'.\n",
      "Total documents in collection 'chrdb.db': 388\n",
      "==((====))==  Unsloth 2025.1.8: Fast Qwen2 patching. Transformers: 4.46.1.\n",
      "   \\\\   /|    GPU: Tesla V100-SXM2-32GB. Max memory: 31.739 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.4.1+cu121. CUDA: 7.0. CUDA Toolkit: 12.1. Triton: 3.0.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Blockwise quantization only supports 16/32-bit floats, but got torch.uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m      7\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipe_eval(verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# verbose를 False로 하면 print가 되지 않습니다.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# collection_name = 'chrdb.db',\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# persist_directory = 'DB',\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# mode = 'NaverCloudEmb'\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# topk = 5\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# verbose = True : answer과 score을 보여줍니다. 보고싶지 않다면 False로 하면 됩니다.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# default로 지정돼 있습니다. 클래스 선언 때 건네주면 바뀝니다.\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQwen32B\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/clone/src/modules/Pipeline/Pipe_for_evaluation.py:57\u001b[0m, in \u001b[0;36mPipeline_For_Eval.setup\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m Qwen14BModel()\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQwen32B\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mQwen32BModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExaone\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m ExaoneModel()\n",
      "File \u001b[0;32m~/clone/src/modules/QA_model/qwen32b.py:9\u001b[0m, in \u001b[0;36mQwen32BModel.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Load the Gemma 27B model\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mFastLanguageModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43munsloth/DeepSeek-R1-Distill-Qwen-32B-bnb-4bit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Automatically picks float16 for A100/H100, float32 for CPU\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Load with 4-bit quantization\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     17\u001b[0m     FastLanguageModel\u001b[38;5;241m.\u001b[39mfor_inference(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/unsloth/models/loader.py:258\u001b[0m, in \u001b[0;36mFastLanguageModel.from_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, use_exact_model_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m     tokenizer_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mdispatch_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_get_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_patcher\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdispatch_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_peft\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resize_model_vocab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m     model\u001b[38;5;241m.\u001b[39mresize_token_embeddings(resize_model_vocab)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/unsloth/models/qwen2.py:87\u001b[0m, in \u001b[0;36mFastQwen2Model.from_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\n\u001b[1;32m     74\u001b[0m     model_name        \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen/Qwen2-7B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     86\u001b[0m ):\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFastLlamaModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_patcher\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFastQwen2Model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/unsloth/models/llama.py:1691\u001b[0m, in \u001b[0;36mFastLlamaModel.from_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, **kwargs)\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[38;5;66;03m# Cannot be None, since HF now checks for the config\u001b[39;00m\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit: kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m bnb_config\n\u001b[0;32m-> 1691\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# quantization_config     = bnb_config,\u001b[39;49;00m\n\u001b[1;32m   1696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_implementation\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meager\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1700\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1701\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# Return old flag\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHF_HUB_ENABLE_HF_TRANSFER\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m old_hf_transfer\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:4225\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4216\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4218\u001b[0m     (\n\u001b[1;32m   4219\u001b[0m         model,\n\u001b[1;32m   4220\u001b[0m         missing_keys,\n\u001b[1;32m   4221\u001b[0m         unexpected_keys,\n\u001b[1;32m   4222\u001b[0m         mismatched_keys,\n\u001b[1;32m   4223\u001b[0m         offload_index,\n\u001b[1;32m   4224\u001b[0m         error_msgs,\n\u001b[0;32m-> 4225\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   4229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4232\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4233\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4236\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4237\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4243\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4245\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   4246\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:4728\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path, weights_only)\u001b[0m\n\u001b[1;32m   4724\u001b[0m                 set_module_tensor_to_device(\n\u001b[1;32m   4725\u001b[0m                     model_to_load, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m*\u001b[39mparam\u001b[38;5;241m.\u001b[39msize(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   4726\u001b[0m                 )\n\u001b[1;32m   4727\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4728\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4729\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4730\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4731\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4732\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4733\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4734\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4735\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4736\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4737\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4738\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4739\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4740\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4741\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4742\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4743\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4744\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   4745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4746\u001b[0m     \u001b[38;5;66;03m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:995\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys, pretrained_model_name_or_path)\u001b[0m\n\u001b[1;32m    993\u001b[0m     set_module_tensor_to_device(model, param_name, param_device, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mset_module_kwargs)\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 995\u001b[0m     \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_quantized_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;66;03m# For quantized modules with FSDP/DeepSpeed Stage 3, we need to quantize the parameter on the GPU\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;66;03m# and then cast it to CPU to avoid excessive memory usage on each GPU\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;66;03m# in comparison to the sharded model across GPUs.\u001b[39;00m\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_fsdp_enabled() \u001b[38;5;129;01mor\u001b[39;00m is_deepspeed_zero3_enabled():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/quantizers/quantizer_bnb_4bit.py:238\u001b[0m, in \u001b[0;36mBnb4BitHfQuantizer.create_quantized_param\u001b[0;34m(self, model, param_value, param_name, target_device, state_dict, unexpected_keys)\u001b[0m\n\u001b[1;32m    235\u001b[0m         new_value \u001b[38;5;241m=\u001b[39m new_value\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    237\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m old_value\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m--> 238\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParams4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m new_value\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:331\u001b[0m, in \u001b[0;36mParams4bit.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m device, dtype, non_blocking, convert_to_format \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39m_parse_to(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m device\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbnb_quantized:\n\u001b[0;32m--> 331\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_quantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:296\u001b[0m, in \u001b[0;36mParams4bit._quantize\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_quantize\u001b[39m(\u001b[38;5;28mself\u001b[39m, device):\n\u001b[1;32m    295\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 296\u001b[0m     w_4bit, quant_state \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize_4bit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompress_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquant_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquant_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m w_4bit\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_state \u001b[38;5;241m=\u001b[39m quant_state\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/functional.py:1243\u001b[0m, in \u001b[0;36mquantize_4bit\u001b[0;34m(A, absmax, out, blocksize, compress_statistics, quant_type, quant_storage)\u001b[0m\n\u001b[1;32m   1241\u001b[0m             lib\u001b[38;5;241m.\u001b[39mcquantize_blockwise_fp32_nf4(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1243\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlockwise quantization only supports 16/32-bit floats, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1245\u001b[0m code \u001b[38;5;241m=\u001b[39m get_4bit_type(quant_type, device\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compress_statistics:\n",
      "\u001b[0;31mValueError\u001b[0m: Blockwise quantization only supports 16/32-bit floats, but got torch.uint8"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "project_root = os.getcwd()\n",
    "sys.path.append(project_root + '/modules')\n",
    "# Pipeline의 구조를 이해하기 쉽게 하기 위해 작성한 ipynb 파일입니다\n",
    "from modules.Pipeline import pipe_eval\n",
    "pipe = pipe_eval(verbose = True) # verbose를 False로 하면 print가 되지 않습니다.\n",
    "# collection_name = 'chrdb.db',\n",
    "# persist_directory = 'DB',\n",
    "# mode = 'NaverCloudEmb'\n",
    "# topk = 5\n",
    "# verbose = True : answer과 score을 보여줍니다. 보고싶지 않다면 False로 하면 됩니다.\n",
    "# default로 지정돼 있습니다. 클래스 선언 때 건네주면 바뀝니다.\n",
    "pipe.setup(model = 'GPT')\n",
    "#                   가능한 모델 (default GPT)\n",
    "#                   1. GPT\n",
    "#                   2. Exaone\n",
    "#                   3. Qwen14B\n",
    "#                   4. Qwen32B\n",
    "#                   5. HyperClova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='교보증권의 분기별 실적 추이를 나타내는 표이다. 각 분기별로 매출액, 영업이익, 순이익 등 주요 지표들이 표시되어 있으며, 이를 통해 해당 기업의 경영 성과를 파악할 수 있다.' metadata={'id': 30, 'type': 'paragraph', 'image_route': nan, 'dir_route': 'datas/네이버_교보증권(2024.11.11)', 'file_name': '네이버_교보증권(2024.11.11).pdf', 'page': 2, 'investment': '교보증권(2024.11.11)', 'company_name': '네이버', 'table': nan, 'original_content': '1Q22 2Q22 3Q22 4Q22 1Q23 2Q23 3Q23 4Q23 1Q24 2Q24 3Q24'}\n",
      "page_content='카카오뱅크가 자산 성장 지속과 함께 2030년 ROE 15% 목표를 달성하려면 당기순이익이 1.3조 원까지 증가해야 하며, 이는 24년 예상이익 대비 198.6% 증가와 연평균 20% 수준의 이익 성장률을 의미한다. 이는 동사가 언급한 영업이익의 연평균 15% 이상 성장 목표를 상회하는 수준이다.' metadata={'id': 57, 'type': 'paragraph', 'image_route': nan, 'dir_route': 'datas/카카오뱅크_삼성증권(2024.11.27)', 'file_name': '카카오뱅크_삼성증권(2024.11.27).pdf', 'page': 4, 'investment': '삼성증권(2024.11.27)', 'company_name': '카카오뱅크', 'table': nan, 'original_content': '동사가 자산 성장의 지속과 더불어 2030년 ROE 15% 목표를 달성하기 위해서는 동사 당기순이익이 1.3 조원까지 증가할 필요가 있음. 이는 ’24년 예상이익 4,400억원대비 198.6% 증가를 의미하며, 연평균 20% 수준의 이익 성장률을 의미함. 참고로, 이는 동사가 계획 상 언급한 동사 영업이익의 연평균 15% 이상 성장 목표를 다소 상회하는 수준의 이익 증가속도를 시사.'}\n",
      "page_content='네이버의 3분기 실적은 매출액 2.7조 원, 영업이익 5,253억 원으로 전년 동기 대비 각각 11.1%, 38.2% 상승하였으며, 이는 컨센서스를 상회하는 수치이다. 특히 디스플레이 광고가 시장 회복 지연에도 불구하고 고효율 상품 확대로 11.0% 성장한 것이 고무적이며, 효율적인 리소스 배치로 수익성이 꾸준히 개선되고 있다.' metadata={'id': 6, 'type': 'paragraph', 'image_route': nan, 'dir_route': 'datas/네이버_SK증권(2024.11.18)', 'file_name': '네이버_SK증권(2024.11.18).pdf', 'page': 1, 'investment': 'SK증권(2024.11.18)', 'company_name': '네이버', 'table': nan, 'original_content': '매출액 2.7 조원(+11.1% YoY, 이하 동일), 영업이익 5,253 억원(+38.2%), 지배주주 순이익 5,204 억원(+38.5%)으로 영업이익은 컨센서스를 상회했다. 서치플랫폼이 +11.0% 성장하며 예상을 상회했다. 검색광고(+9.5%)는 견조, 특히 디스플레이 광고 가 시장 회복 지연에도 불구하고 고효율 상품 확대로 +11.0% 성장한 점이 고무적이 다. 영업비용은 커머스 프로모션 확대로 마케팅비가 증가했음에도 전체 비용이 +6.1% 증가에 그치며 잘 통제되는 모습을 보였다. 효율적인 리소스 배치로 수익성은 꾸준히 개선되고 있다(OPM: 1Q23 14.5%-> 4Q23 16.0%-> 3Q24 19.3%).'}\n",
      "page_content='카카오뱅크는 28년부터 자산성장률이 15%로 둔화될 것으로 예상되며, 이는 동사의 연평균 영업이익 성장률 및 지속 성장 기조를 고려한 결과이다.' metadata={'id': 63, 'type': 'paragraph', 'image_route': nan, 'dir_route': 'datas/카카오뱅크_삼성증권(2024.11.27)', 'file_name': '카카오뱅크_삼성증권(2024.11.27).pdf', 'page': 4, 'investment': '삼성증권(2024.11.27)', 'company_name': '카카오뱅크', 'table': nan, 'original_content': '한편, ’28년 이후의 자산성장에 대한 목표는 금번 계획에 포함되지 않았음. 다만, 우리는 ’28년부터는 자산성장률이 15%로 소폭 둔화되는 것으로 가정하였는데, 이는 동사의 연평균 영업이익 성장률 15%와 지속 성장 기조를 감안하였기 때문.'}\n",
      "page_content='LG화학의 4분기 영업이익은 GM 등의 연말 재고 조정 영향으로 출하량/AMPC가 축소되어  LGES 영업 이익이 적자 전환하고, 양극재를 중심으로 첨단소재 영업이익도 감소할 것으로 추정되나 환율 상승과 원료가/운임 하락에 따른 영향 덕분에 석유화학 영업이익은 개선 될 것으로 예상 된다.' metadata={'id': 7, 'type': 'paragraph', 'image_route': nan, 'dir_route': 'datas/LG화학_하나증권(2024.10.29)', 'file_name': 'LG화학_하나증권(2024.10.29).pdf', 'page': 1, 'investment': '하나증권(2024.10.29)', 'company_name': 'LG화학', 'table': nan, 'original_content': '4Q24 영업이익은 -1,123억원(QoQ 적전, YoY 적전)으로 현재 컨센서스(5,665억원)을 크게 하회할 전망이다. GM 등의 연말 재고 조정 영향으로 출하량/AMPC가 축소되어 LGES 영업 이익이 적자전환(-2천억원)하고, 이에 따라 양극재를 중심으로 첨단소재 영업이익도 감소할 것으로 추정되기 때문이다. 석유화학 영업이익은 255억원(QoQ 흑전)으로 개선이 예상된다. 환율 상승과 원료가/운임 하락에 따른 영향 덕분이다. 중국의 통화/재정 정책 등에 따른 시 황의 점진적 개선도 예상된다. 첨단소재 영업이익은 1,033억원으로 QoQ -31% 감익을 추정 한다. IT/반도체소재/EP 모두 연말 재고조정 등 영향으로 수익성이 감소하고, 양극재 또한 영업이익이 120억원(OPM 2.3%)으로 감소하기 때문이다. 양극재의 판가는 QoQ -10%, 판 매량은 QoQ -30% 축소될 것으로 추정되며, 이에 따라 전분기 대비 수익성도 약화될 것으 로 예상한다.'}\n"
     ]
    }
   ],
   "source": [
    "# query = 'SK하이닉스의 2025~2027년 주주환원 정책에서 변경된 고정배당금과 추가 배당금의 활용 방안은 무엇인가요?'\n",
    "query = 'NAVER의 분기별 실적 추이 및 전망에 대하여 알려줘'\n",
    "# validation데이터셋의 첫번째 question\n",
    "retrieval_result = pipe.Q(query, mode = 'ensemble')\n",
    "# bm25, dpr, ensemble 가능 (default 'ensemble')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(retrieval_result[1].metadata['table'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "다음 참고 문서를 반드시 활용하여 질문에 대한 정확하고 간결한 답변을 작성하세요. \n",
      "답변은 반드시 질문과 관련된 사실에 기반하며, 불필요한 반복이나 모호함 없이 핵심 내용을 포함해야 합니다. \n",
      "200자를 초과하지 않도록 작성하세요.\n",
      "\n",
      "질문: SK하이닉스의 2025~2027년 주주환원 정책에서 변경된 고정배당금과 추가 배당금의 활용 방안은 무엇인가요?\n",
      "참고 문서1: SK하이닉스는 장 종료 후에 향후 3개년간 주주환원 쟁책을 공시했다. 기존 3개년 주주환 원 정책에서 변화가 생겼다. 변경된 부분의 핵심은 연간 고정배당금을 기존 1,200원에서 1,500원으로 상향하고, 기존 정책 하에서 지급하던 추가 배당금이었던 연간 Free Cash Flow의 5% 재원을 재무 건전성 강화에 우선 활용한다는 점이다. 아울러 정책 종료 후 총 재원 안에서 재무 건전성 목표가 달성되면 추가 환원을 실행하거나, 유의미한 수준의 Free Cash Flow 창출이 예상되는 경우에 조기 환원도 가능하다고 언급했다. 다시 설명하 자면 2025~2027년까지 3년 누적 Free Cash Flow의 50% 수준을 총 재원으로 설정하는 것은 기존과 동일하다. 다만, 기존에 매년 지급하던 FCF 내 5%의 추가 배당금을 앞으로 는 재무 건전성 강화로 사용하는 대신에 정책 종료 후 FCF 50% 수준 안에서 여유 재원을 기반으로 한 추가 환원을 결정한 것이다. 메모리 업황 특성상 변동성이 크기 때문에 예측 가능한 주주환원 규모를 선정하기 어렵기 때문에 3년 누적의 Free Cash Flow 선정은 동종 업체들의 정책과도 일맥상통하는 부분이다. 또한, SK하이닉스의 재무 건전성이 경쟁사들보 다 열위에 있던 점을 고려하면 금번 주주환원 정책 발표는 합리적인 결정이라 판단한다.\n",
      "참고 문서2: 기업가치 제고계획 목표 4. ’24~’25년 주주환원율 50% 도달 이후 ’27년부터 DPS 유지 또 는 점진적 상향 – 배당 중심 주주환원 정책 예상: 동사의 주주환원 정책은 자사주 매입 및 소각보다는 배당 확대가 보다 현실적일 것으로 판단. 이에, DPS는 주주환원율 상향 계획에 따라 2026년까지 고성장을 지속한 후, 이익 증가 속도와 유사한 흐름을 전망.\n",
      "참고 문서3: 일차적으로 동사의 DPS는 ’26년까지 고성장을 보일 것으로 전망. 이는 동사의 두 자릿수 자산 및 이익 성장과 더불어 주주환원율이 점진적으로 높아지고, 주주환원은 배당을 중심으로 이뤄질 것으로 가정하 였기 때문.\n",
      "참고 문서4: 4. 목표: ’24~’26년 주주환원율 50% 도달 이후 ’27년부터 DPS 유지 또는 점진적 상향 – 시사점: 배당 중심 주주환원 정책 예상\n",
      "참고 문서5: 이번에 발표된 향후 3년간 주주환원 정책과 기업가치 제고 계획에 대해 다소 실망스러운 시장 반응이 있을 수 있다. 다만, 메모리 업종은 주주환원보다 기술 리더십이 우선시 되어 야 한다. 그럼에도 불구하고 변동성 높은 업황 안에서 주주환원을 안정화시키려는 의도에 주목해야 한다는 판단이다. 글로벌 메모리 3사 중 재무 건전성 측면에서 상대적으로 열위 에 있었다는 이유로 밸류에이션 할인이 있었다는 점 또한 부인할 수 없다. 향후에 SK하이 닉스의 재무 건전성이 강화된다면, 중장기적으로 주주환원 강화와 연결될 수 있고, 나아가 밸류에이션 할증에 대한 정당성도 확보할 수 있다는 점을 고려할 필요가 있다.\"\n",
      "정답:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer = pipe.A(query, retrieval_result)\n",
    "# query 와 retrieval 결과를 받아 answer을 냅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025~2027년 SK하이닉스 주주환원 정책은 연간 고정배당금 1,500원을 지급하고, 3년 누적 Free Cash Flow(Fcf)의 50%를 활용해 추가 환원을 진행할 계획입니다.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='SK하이닉스는 향후 3개년간 주주환원 정책을 공시하며, 연간 고정배당금을 1,500원으로 상향하고,  Free Cash Flow의 5% 재원을 재무 건전성 강화에 우선 활용한다고 밝혔다. 이는 메모리 업황 특성상 변동성이 큰 상황에서 내린 합리적인 결정이라고 판단된다.' metadata={'company_name': 'SK하이닉스', 'dir_route': 'datas/SK하이닉스_하나증권(2024.11.28)', 'file_name': 'SK하이닉스_하나증권(2024.11.28).pdf', 'id': 17, 'investment': '하나증권(2024.11.28)', 'original_content': 'SK하이닉스는 장 종료 후에 향후 3개년간 주주환원 쟁책을 공시했다. 기존 3개년 주주환 원 정책에서 변화가 생겼다. 변경된 부분의 핵심은 연간 고정배당금을 기존 1,200원에서 1,500원으로 상향하고, 기존 정책 하에서 지급하던 추가 배당금이었던 연간 Free Cash Flow의 5% 재원을 재무 건전성 강화에 우선 활용한다는 점이다. 아울러 정책 종료 후 총 재원 안에서 재무 건전성 목표가 달성되면 추가 환원을 실행하거나, 유의미한 수준의 Free Cash Flow 창출이 예상되는 경우에 조기 환원도 가능하다고 언급했다. 다시 설명하 자면 2025~2027년까지 3년 누적 Free Cash Flow의 50% 수준을 총 재원으로 설정하는 것은 기존과 동일하다. 다만, 기존에 매년 지급하던 FCF 내 5%의 추가 배당금을 앞으로 는 재무 건전성 강화로 사용하는 대신에 정책 종료 후 FCF 50% 수준 안에서 여유 재원을 기반으로 한 추가 환원을 결정한 것이다. 메모리 업황 특성상 변동성이 크기 때문에 예측 가능한 주주환원 규모를 선정하기 어렵기 때문에 3년 누적의 Free Cash Flow 선정은 동종 업체들의 정책과도 일맥상통하는 부분이다. 또한, SK하이닉스의 재무 건전성이 경쟁사들보 다 열위에 있던 점을 고려하면 금번 주주환원 정책 발표는 합리적인 결정이라 판단한다.', 'page': 1, 'type': 'paragraph'}\n",
      "page_content='SK하이닉스의 이번 주주환원 정책과 기업가치 제고 계획에 시장 반응은 실망스러울 수 있지만, 메모리 업종에서는 기술 리더십이 중요하며, 재무 건정성이 강화되면 중장기적으로 주주환원 강화와 연결되어 밸류에이션 할증에 대한 정당성을 확보할 수 있음을 고려해야 함' metadata={'company_name': 'SK하이닉스', 'dir_route': 'datas/SK하이닉스_하나증권(2024.11.28)', 'file_name': 'SK하이닉스_하나증권(2024.11.28).pdf', 'id': 21, 'investment': '하나증권(2024.11.28)', 'original_content': '이번에 발표된 향후 3년간 주주환원 정책과 기업가치 제고 계획에 대해 다소 실망스러운 시장 반응이 있을 수 있다. 다만, 메모리 업종은 주주환원보다 기술 리더십이 우선시 되어 야 한다. 그럼에도 불구하고 변동성 높은 업황 안에서 주주환원을 안정화시키려는 의도에 주목해야 한다는 판단이다. 글로벌 메모리 3사 중 재무 건전성 측면에서 상대적으로 열위 에 있었다는 이유로 밸류에이션 할인이 있었다는 점 또한 부인할 수 없다. 향후에 SK하이 닉스의 재무 건전성이 강화된다면, 중장기적으로 주주환원 강화와 연결될 수 있고, 나아가 밸류에이션 할증에 대한 정당성도 확보할 수 있다는 점을 고려할 필요가 있다.', 'page': 1, 'type': 'paragraph'}\n",
      "page_content='카카오뱅크는 2024년부터 26년까지 주주 환원율 50% 달성 후 27년부터 주당 배당금(DPS) 유지 또는 점진적으로 늘릴 계획이며, 이를 통해 배당 중심의 주주 환원 정책을 시행할 것으로 예상된다.' metadata={'company_name': '카카오뱅크', 'dir_route': 'datas/카카오뱅크_삼성증권(2024.11.27)', 'file_name': '카카오뱅크_삼성증권(2024.11.27).pdf', 'id': 80, 'investment': '삼성증권(2024.11.27)', 'original_content': '4. 목표: ’24~’26년 주주환원율 50% 도달 이후 ’27년부터 DPS 유지 또는 점진적 상향 – 시사점: 배당 중심 주주환원 정책 예상', 'page': 5, 'type': 'paragraph'}\n",
      "page_content='SK하이닉스는 향후 3년간 매출액 대비 CapEx 30% 중반을 목표로 하며, HBM 등 기술 리더십을 유지하면서 동시에 재무 건정성을 기반으로 한 주주환원 정책을 추진할 계획이다. 또한 안정적인 이익 창출과 재무 건전성의 강화를 바탕으로 지속적이고 균형 있는 주주환원을 계속하겠다고 밝혔다.' metadata={'company_name': 'SK하이닉스', 'dir_route': 'datas/SK하이닉스_하나증권(2024.11.28)', 'file_name': 'SK하이닉스_하나증권(2024.11.28).pdf', 'id': 19, 'investment': '하나증권(2024.11.28)', 'original_content': '주주환원과 더불어 기업가치 제고 계획도 공시했다. 3개년 이동평균 기준으로 매출액대비 CapEx 30% 중반을 목표로 하고, HBM 기반으로 기술 리더십을 유지하되, 재무 건전성을 기반으로 한 주주환원 정책을 언급했다. 매출액대비 30% 중반 수준의 CapEx는 기존에 유지하던 수익성 기반의 투자 기조와 과거보다 상향된 투자 금액을 고려한 기준이라 판단 한다. 아울러 HBM을 계기로 기술 리더십을 확보한 AI 및 차세대 메모리 기술에 있어서는 물량보다 적기 기술 확보를 핵심으로 투자할 전망이다. 마지막으로 주주환원 정책에서도 강조했던 것처럼 안정적인 이익 창출과 재무 건전성 강화를 기반으로 지속적이고 균형 있 는 주주환원을 지속할 것을 언급했다.', 'page': 1, 'type': 'paragraph'}\n",
      "page_content='카카오뱅크는 2024년에서 2025년까지 주주 환원율 50% 달성 후, 27년부터는 주당배당금(DPS)유지 또는 점진적 상승을 통한 배당 중심의 주주환원 정책을 펼칠 것으로 예상되며, 이를 위해 26년까지 높은 성장률을 이어갈 것으로 전망된다.' metadata={'id': 21, 'type': 'paragraph', 'image_route': nan, 'dir_route': 'datas/카카오뱅크_삼성증권(2024.11.27)', 'file_name': '카카오뱅크_삼성증권(2024.11.27).pdf', 'page': 1, 'investment': '삼성증권(2024.11.27)', 'company_name': '카카오뱅크', 'table': nan, 'original_content': '기업가치 제고계획 목표 4. ’24~’25년 주주환원율 50% 도달 이후 ’27년부터 DPS 유지 또 는 점진적 상향 – 배당 중심 주주환원 정책 예상: 동사의 주주환원 정책은 자사주 매입 및 소각보다는 배당 확대가 보다 현실적일 것으로 판단. 이에, DPS는 주주환원율 상향 계획에 따라 2026년까지 고성장을 지속한 후, 이익 증가 속도와 유사한 흐름을 전망.'}\n",
      "\n",
      "다음 참고 문서를 반드시 활용하여 질문에 대한 정확하고 간결한 답변을 작성하세요. \n",
      "답변은 반드시 질문과 관련된 사실에 기반하며, 불필요한 반복이나 모호함 없이 핵심 내용을 포함해야 합니다. \n",
      "200자를 초과하지 않도록 작성하세요.\n",
      "\n",
      "질문: SK하이닉스의 2025~2027년 주주환원 정책에서 변경된 고정배당금과 추가 배당금의 활용 방안은 무엇인가요?\n",
      "참고 문서1: SK하이닉스는 장 종료 후에 향후 3개년간 주주환원 쟁책을 공시했다. 기존 3개년 주주환 원 정책에서 변화가 생겼다. 변경된 부분의 핵심은 연간 고정배당금을 기존 1,200원에서 1,500원으로 상향하고, 기존 정책 하에서 지급하던 추가 배당금이었던 연간 Free Cash Flow의 5% 재원을 재무 건전성 강화에 우선 활용한다는 점이다. 아울러 정책 종료 후 총 재원 안에서 재무 건전성 목표가 달성되면 추가 환원을 실행하거나, 유의미한 수준의 Free Cash Flow 창출이 예상되는 경우에 조기 환원도 가능하다고 언급했다. 다시 설명하 자면 2025~2027년까지 3년 누적 Free Cash Flow의 50% 수준을 총 재원으로 설정하는 것은 기존과 동일하다. 다만, 기존에 매년 지급하던 FCF 내 5%의 추가 배당금을 앞으로 는 재무 건전성 강화로 사용하는 대신에 정책 종료 후 FCF 50% 수준 안에서 여유 재원을 기반으로 한 추가 환원을 결정한 것이다. 메모리 업황 특성상 변동성이 크기 때문에 예측 가능한 주주환원 규모를 선정하기 어렵기 때문에 3년 누적의 Free Cash Flow 선정은 동종 업체들의 정책과도 일맥상통하는 부분이다. 또한, SK하이닉스의 재무 건전성이 경쟁사들보 다 열위에 있던 점을 고려하면 금번 주주환원 정책 발표는 합리적인 결정이라 판단한다.\n",
      "참고 문서2: 이번에 발표된 향후 3년간 주주환원 정책과 기업가치 제고 계획에 대해 다소 실망스러운 시장 반응이 있을 수 있다. 다만, 메모리 업종은 주주환원보다 기술 리더십이 우선시 되어 야 한다. 그럼에도 불구하고 변동성 높은 업황 안에서 주주환원을 안정화시키려는 의도에 주목해야 한다는 판단이다. 글로벌 메모리 3사 중 재무 건전성 측면에서 상대적으로 열위 에 있었다는 이유로 밸류에이션 할인이 있었다는 점 또한 부인할 수 없다. 향후에 SK하이 닉스의 재무 건전성이 강화된다면, 중장기적으로 주주환원 강화와 연결될 수 있고, 나아가 밸류에이션 할증에 대한 정당성도 확보할 수 있다는 점을 고려할 필요가 있다.\n",
      "참고 문서3: 4. 목표: ’24~’26년 주주환원율 50% 도달 이후 ’27년부터 DPS 유지 또는 점진적 상향 – 시사점: 배당 중심 주주환원 정책 예상\n",
      "참고 문서4: 주주환원과 더불어 기업가치 제고 계획도 공시했다. 3개년 이동평균 기준으로 매출액대비 CapEx 30% 중반을 목표로 하고, HBM 기반으로 기술 리더십을 유지하되, 재무 건전성을 기반으로 한 주주환원 정책을 언급했다. 매출액대비 30% 중반 수준의 CapEx는 기존에 유지하던 수익성 기반의 투자 기조와 과거보다 상향된 투자 금액을 고려한 기준이라 판단 한다. 아울러 HBM을 계기로 기술 리더십을 확보한 AI 및 차세대 메모리 기술에 있어서는 물량보다 적기 기술 확보를 핵심으로 투자할 전망이다. 마지막으로 주주환원 정책에서도 강조했던 것처럼 안정적인 이익 창출과 재무 건전성 강화를 기반으로 지속적이고 균형 있 는 주주환원을 지속할 것을 언급했다.\n",
      "참고 문서5: 기업가치 제고계획 목표 4. ’24~’25년 주주환원율 50% 도달 이후 ’27년부터 DPS 유지 또 는 점진적 상향 – 배당 중심 주주환원 정책 예상: 동사의 주주환원 정책은 자사주 매입 및 소각보다는 배당 확대가 보다 현실적일 것으로 판단. 이에, DPS는 주주환원율 상향 계획에 따라 2026년까지 고성장을 지속한 후, 이익 증가 속도와 유사한 흐름을 전망.\"\n",
      "정답:\n",
      "SK하이닉스의 ****-****년 주주환원 정책에서 변경된 고정배당금은 기존 1,200원에서 1,500원으로 상향되었고, 추가 배당금이었던 연간 Free Cash Flow의 5% 재원은 재무 건전성 강화에 우선 활용됩니다. 정책 종료 후 총 재원 안에서 재무 건전성 목표가 달성되면 추가 환원을 실행하거나, 유의미한 수준의 Free Cash Flow 창출이 예상되는 경우에 조기 환원도 가능합니다.\n"
     ]
    }
   ],
   "source": [
    "answer = pipe.QA(query, mode = 'ensemble')\n",
    "# QA를 따로 내는 것이 아니라 한번에 정답을 얻을 수도 있습니다. 이후 정량평가에서는 QA를 사용하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='한화솔루션의 신재생에너지 부문은 4분기 매출액 1조 원, 영업이익 520억 원으로 흑자 전환 예상됨. 다만, 미국 내 과잉 재고와 시장 가격 약세로 조기 수익성 확보는 어려울 것으로 전망함. 동남아시아 및 대중국 태양광 관세 부과와 금리 인하 이후 미국 내 태양광 발전 수요 증가를 회복 변수로 판단함.' metadata={'company_name': '한화솔루션', 'dir_route': 'datas/한화솔루션_메리츠증권(2024.10.31)', 'file_name': '한화솔루션_메리츠증권(2024.10.31).pdf', 'id': 10, 'investment': '메리츠증권(2024.10.31)', 'original_content': '당사의 기존 신재생에너지부문 4Q24 추정은 매출액 1.0조원, 영업이익 520억 원으로 흑자전환은 가능할 점. AMPC 1,613억원을 추정, 이를 제외한 영업적자 는 -1,093억원. 미국 달튼 공장의 생산량 소폭 증가, 반면 미국 내 과잉재고, 시장가격 약세흐름에 조기 수익성 확보는 다소 요원해질 점. 태양광 업황 변수 는 2025년 동남아/대중 태양광 관세부과에 시장가격 상승 가능성, 금리인하 이 후 미국 내 태양광 발전수요 증가에 생산현지화의 이점 반영 가능성 등을 회복 변수로 판단', 'page': 1, 'type': 'paragraph'}\n",
      "page_content='한화솔루션은 분기 영업실적에서 매출액 2.7조원, 영업적자 -810억원을 기록하며 이는 신재생부문 EPC 자산매각 규모가 가이던스에 미치지 못한 것이 원인이다.' metadata={'company_name': '한화솔루션', 'dir_route': 'datas/한화솔루션_메리츠증권(2024.10.31)', 'file_name': '한화솔루션_메리츠증권(2024.10.31).pdf', 'id': 6, 'investment': '메리츠증권(2024.10.31)', 'original_content': '한화솔루션은 당분기 영업실적 매출액 2.7조원, 영업적자 -810억원을 기록. 이는 매출액 및 영업이익 모두 시장/당사 예상치를 하회한 실적. 예상치 하회 배경은 신재생부문 EPC 자산매각 규모가 가이던스에 미치지 못했기 때문. 해 당 금액은 차분기로 이연될 예정으로 연간 가이던스(2.5조원)에는 변동 없어', 'page': 1, 'type': 'paragraph'}\n",
      "page_content='한화솔루션의 4분기 영업이익은 184억원으로 시장 기대치인 745억원보다 낮을 것으로 예상된다. 이는 기초소재 사업의 부진 때문이며, 태양광 사업에서는 흑자 전환이 기대된다. 특히 미국 인플레이션 감축법(IRA) 시행으로 인한 세액공제 혜택으로 태양광 모듈 판매량 증가와 발전사업 매출액 상승이 예상된다.' metadata={'company_name': '한화솔루션', 'dir_route': 'datas/한화솔루션_삼성증권(2024.10.30)', 'file_name': '한화솔루션_삼성증권(2024.10.30).pdf', 'id': 21, 'investment': '삼성증권(2024.10.30)', 'original_content': '4Q24 preview, 컨센서스 하회: 4Q 영업이익은 -184억원(+626억원QoQ)으로 컨센서스(745 억원, Fnguide) 하회 지속 예상되는데, 이는 기초소재 부진(영업이익 -321억원)에 기인. 태 양광 매출 및 영업이익은 각각 2.01조원(+75%QoQ) 및 116억원(흑자 전환QoQ; OPM +0.6%) 예상. 태양광 영업이익은 모듈 제조사업 -1,741억원(+193억원QoQ; OPM -20.7%), 발전사업 272억원(-12%QoQ; OPM +2.3%) 및 IRA AMPC 1,585억원(+30%QoQ)으로 구성 예상. 태양광 모듈 판매량은 전분기 이연 물량을 포함하여 크게 회복 전망(+58%QoQ vs 3Q24: Flat QoQ). 발전사업 매출도 일부 프로젝트 지연분 반영으로 급증 예상(1.17조원; +103%QoQ).', 'page': 1, 'type': 'paragraph'}\n",
      "page_content='한화솔루션의 케미칼 부문은 매출액 1.1조원으로 전분기 대비 2.8% 감소하였고, 대외변수 불확실성과 비용 증가로 인해 영업적자 310억원을 기록했다. 신재생에너지 부문은 영업적자 410억원이지만 자산 매각 및 EPC 반영 308억원, 미국 생산량 증가에 따른 AMPC 수취 1,200억원으로 적자 폭이 축소되었다.' metadata={'company_name': '한화솔루션', 'dir_route': 'datas/한화솔루션_메리츠증권(2024.10.31)', 'file_name': '한화솔루션_메리츠증권(2024.10.31).pdf', 'id': 8, 'investment': '메리츠증권(2024.10.31)', 'original_content': '(1) 케미칼: 매출액 1.1조원(-2.8% QoQ), 영업적자 -310억원(적자확대 QoQ). 대외변수 불확실성 지속과 비용 증가(운임비용 등)는 수익성에 부정적. 또한 역내 주요 제품별 수급 불균형 장기화에 가격 약세 지속은 적자 확대요인 (2) 신재생에너지는 영업적자 -410억원(적자축소 QoQ)을 기록. 개발자산 매 각/EPC 반영(308억원)과 미국 생산량 증가에 따른 AMPC 수취(+1,200억원) 도 적자폭 축소 요인', 'page': 1, 'type': 'paragraph'}\n",
      "page_content='한화솔루션, 2024년 케미칼과 태양광 사업 모두 부진 예상되나 태양광 분야에서는 느린 회복세 전망' metadata={'company_name': '한화솔루션', 'dir_route': 'datas/한화솔루션_메리츠증권(2024.10.31)', 'file_name': '한화솔루션_메리츠증권(2024.10.31).pdf', 'id': 9, 'investment': '메리츠증권(2024.10.31)', 'original_content': '2024년 케미칼과 태양광 부진의 이중고. 태양광은 느리지만 회복은 될 점', 'page': 1, 'type': 'paragraph'}\n",
      "\n",
      "다음 참고 문서를 반드시 활용하여 질문에 대한 정확하고 간결한 답변을 작성하세요. \n",
      "답변은 반드시 질문과 관련된 사실에 기반하며, 불필요한 반복이나 모호함 없이 핵심 내용을 포함해야 합니다. \n",
      "200자를 초과하지 않도록 작성하세요.\n",
      "\n",
      "질문: 한화솔루션의 2024년 4분기 신재생에너지부문에서 예상되는 영업이익과 매출액은 얼마인가요? 또한, 영업적자와 관련된 주요 요인은 무엇인가요?\n",
      "참고 문서1: 당사의 기존 신재생에너지부문 4Q24 추정은 매출액 1.0조원, 영업이익 520억 원으로 흑자전환은 가능할 점. AMPC 1,613억원을 추정, 이를 제외한 영업적자 는 -1,093억원. 미국 달튼 공장의 생산량 소폭 증가, 반면 미국 내 과잉재고, 시장가격 약세흐름에 조기 수익성 확보는 다소 요원해질 점. 태양광 업황 변수 는 2025년 동남아/대중 태양광 관세부과에 시장가격 상승 가능성, 금리인하 이 후 미국 내 태양광 발전수요 증가에 생산현지화의 이점 반영 가능성 등을 회복 변수로 판단\n",
      "참고 문서2: 한화솔루션은 당분기 영업실적 매출액 2.7조원, 영업적자 -810억원을 기록. 이는 매출액 및 영업이익 모두 시장/당사 예상치를 하회한 실적. 예상치 하회 배경은 신재생부문 EPC 자산매각 규모가 가이던스에 미치지 못했기 때문. 해 당 금액은 차분기로 이연될 예정으로 연간 가이던스(2.5조원)에는 변동 없어\n",
      "참고 문서3: 4Q24 preview, 컨센서스 하회: 4Q 영업이익은 -184억원(+626억원QoQ)으로 컨센서스(745 억원, Fnguide) 하회 지속 예상되는데, 이는 기초소재 부진(영업이익 -321억원)에 기인. 태 양광 매출 및 영업이익은 각각 2.01조원(+75%QoQ) 및 116억원(흑자 전환QoQ; OPM +0.6%) 예상. 태양광 영업이익은 모듈 제조사업 -1,741억원(+193억원QoQ; OPM -20.7%), 발전사업 272억원(-12%QoQ; OPM +2.3%) 및 IRA AMPC 1,585억원(+30%QoQ)으로 구성 예상. 태양광 모듈 판매량은 전분기 이연 물량을 포함하여 크게 회복 전망(+58%QoQ vs 3Q24: Flat QoQ). 발전사업 매출도 일부 프로젝트 지연분 반영으로 급증 예상(1.17조원; +103%QoQ).\n",
      "참고 문서4: (1) 케미칼: 매출액 1.1조원(-2.8% QoQ), 영업적자 -310억원(적자확대 QoQ). 대외변수 불확실성 지속과 비용 증가(운임비용 등)는 수익성에 부정적. 또한 역내 주요 제품별 수급 불균형 장기화에 가격 약세 지속은 적자 확대요인 (2) 신재생에너지는 영업적자 -410억원(적자축소 QoQ)을 기록. 개발자산 매 각/EPC 반영(308억원)과 미국 생산량 증가에 따른 AMPC 수취(+1,200억원) 도 적자폭 축소 요인\n",
      "참고 문서5: 2024년 케미칼과 태양광 부진의 이중고. 태양광은 느리지만 회복은 될 점\"\n",
      "정답:\n",
      "한화솔루션의 2024년 4분기 신재생에너지부문 매출액은 1.0조 원, 영업이익은 520억 원으로 예상됩니다. 그러나 AMPC를 제외하면 영업적자는 -1,093억 원입니다. 주요 요인은 미국 내 과잉재고와 시장가격 약세입니다.\n",
      "[query]: 한화솔루션의 2024년 4분기 신재생에너지부문에서 예상되는 영업이익과 매출액은 얼마인가요? 또한, 영업적자와 관련된 주요 요인은 무엇인가요?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[answer]: 한화솔루션의 2024년 4분기 신재생에너지부문 매출액은 1.0조 원, 영업이익은 520억 원으로 예상됩니다. 그러나 AMPC를 제외하면 영업적자는 -1,093억 원입니다. 주요 요인은 미국 내 과잉재고와 시장가격 약세입니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Retrieval score]\n",
      "#### 1. Retrieval Evaluation (20 points):\n",
      "\n",
      "1. **Do any of the retrieved contexts show strong similarity to the Ground Truth?** (5 points)  \n",
      "   **[Yes]** - Justification: The retrieved contexts provide specific figures for expected sales and operating profit for Hanwha Solutions' renewable energy sector in Q4 2024, which closely aligns with the user's query about these metrics.\n",
      "\n",
      "2. **Do the retrieved contexts collectively capture essential information from the Ground Truth?** (5 points)  \n",
      "   **[Yes]** - Justification: The contexts collectively provide a comprehensive overview of the expected sales, operating profit, and the factors contributing to operating losses, which are all critical elements of the user's inquiry.\n",
      "\n",
      "3. **Do the retrieved contexts sufficiently address the user’s question?** (4 points)  \n",
      "   **[Yes]** - Justification: The contexts directly answer the user's question regarding expected sales and operating profit, as well as the reasons for operating losses, thus fully addressing the inquiry.\n",
      "\n",
      "4. **Are all retrieved contexts relevant to the Ground Truth or the user’s query?** (3 points)  \n",
      "   **[Yes]** - Justification: All retrieved documents pertain to Hanwha Solutions and discuss the renewable energy sector, making them relevant to the user's query about the company's performance in that area.\n",
      "\n",
      "5. **Does the combined length and number of retrieved contexts remain reasonable without overwhelming the user with excessive or irrelevant details?** (3 points)  \n",
      "   **[Yes]** - Justification: The number of retrieved contexts is manageable, and the information provided is concise and directly related to the query, ensuring clarity without overwhelming the user.\n",
      "\n",
      "**Total Retrieval Score**: [20 / 20]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Generation score]\n",
      "#### 1. Generation Evaluation (30 points):\n",
      "\n",
      "1. **Is the final answer clearly relevant to the question and reflective of the user’s intent?** (5 points)  \n",
      "   [Yes] - Justification: The generated answer directly addresses the user's query about the expected sales and operating profit for Hanwha Solutions' renewable energy sector in Q4 2024, as well as the reasons for the operating loss.\n",
      "\n",
      "2. **Is the answer factually correct and free from unsupported or inaccurate information?** (5 points)  \n",
      "   [Yes] - Justification: The figures provided in the generated answer match those in the ground truth answer, indicating that the information is factually correct.\n",
      "\n",
      "3. **Does the answer include all essential points required by the question and the ground_truth_answer?** (5 points)  \n",
      "   [Yes] - Justification: The generated answer includes the expected sales, operating profit, operating loss, and the main reasons for the loss, covering all essential points.\n",
      "\n",
      "4. **Is the answer clear and concise, avoiding unnecessary repetition or ambiguity?** (5 points)  \n",
      "   [Yes] - Justification: The answer is straightforward and avoids unnecessary repetition, presenting the information in a clear manner.\n",
      "\n",
      "5. **Is the answer logically structured, consistent with the context, and free of contradictions?** (3 points)  \n",
      "   [Yes] - Justification: The answer is logically structured, presenting the expected figures first, followed by the operating loss and its reasons, with no contradictions present.\n",
      "\n",
      "6. **Does the answer provide sufficient detail for the question without being excessive?** (3 points)  \n",
      "   [Yes] - Justification: The answer provides all necessary details without overwhelming the user with excessive information.\n",
      "\n",
      "7. **Does the answer provide proper citations or indications of the source when claims or data are referenced?** (2 points)  \n",
      "   [No] - Justification: The generated answer does not provide any citations or indications of the source of the data, which is a missed opportunity for credibility.\n",
      "\n",
      "8. **Is the answer presented in a suitable format (list, table, short text, etc.) for the question?** (1 point)  \n",
      "   [Yes] - Justification: The answer is presented in a clear text format that is appropriate for the question asked.\n",
      "\n",
      "9. **Does the answer offer any helpful extra insights or context that enrich the user’s understanding (without deviating from factual correctness)?** (1 point)  \n",
      "   [No] - Justification: The answer does not provide any additional insights or context beyond the factual information requested.\n",
      "\n",
      "**Total Generation Score**: 26 / 30\n"
     ]
    }
   ],
   "source": [
    "generated_answer, G_retrieval_score, G_generation_score = pipe.QA_eval(mode = 'ensemble', sampling = True)\n",
    "\n",
    "# validation 데이터셋의 무작위 샘플을 가져와 G-eval로 평가할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "267it [1:42:57, 23.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267 에 대한 평가를 마쳤습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_df = pipe.QA_eval(mode = 'ensemble', sampling = False) # sampling이 False일 경우, 모든 validation 데이터셋에 대해 평가를 진행합니다.\n",
    "# 구현이 귀찮아서 일단 ./datas/g_eval_result_{model_name}.csv 경로에 저장되도록 하였습니다.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# retrieval G eval score과 generation G eval score의 점수 부분만 파싱합니다. (저장된 csv에는 전부 문자로 돼 있습니다.)\n",
    "\n",
    "eval_df['generation_score'] = eval_df['generation_score'].apply(lambda x: x[x.rfind('/')-3:x.rfind('/')])\n",
    "eval_df['retrieval_score'] = eval_df['retrieval_score'].apply(lambda x: x[x.rfind('/')-3:x.rfind('/')])\n",
    "eval_df['generation_score'] = pd.to_numeric(eval_df['generation_score'], errors = 'coerce')\n",
    "eval_df['retrieval_score'] = pd.to_numeric(eval_df['retrieval_score'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    262.000000\n",
       "mean      24.194656\n",
       "std        3.470220\n",
       "min       12.000000\n",
       "25%       22.000000\n",
       "50%       26.000000\n",
       "75%       26.000000\n",
       "max       30.000000\n",
       "Name: generation_score, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['generation_score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paragraph'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_result[0].metadata['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = \"\"\"|---------------------|--------|--------|-------|-------|-------|\n",
    "| 매출액              | 1,829  | 1,749  | 1,906 | 1,706 | 1,936 |\n",
    "| 영업이익            | 230    | 83     | 106   | 123   | 139   |\n",
    "| (증감률)            | -58.5  | -63.9  | 27.8  | 15.9  | 13.0  |\n",
    "| 지배주주순이익      | -      | -      | -     | -     | -     |\n",
    "| EPS                 | 10.73  | 10.71  | 11.5  | 12.0  | 12.5  |\n",
    "| PER (H/L)           | 14.5   | 38.9   | 24.3  | 11.5  | 10.5  |\n",
    "| PBR (H/L)           | 1.40   | 0.78   | 0.73  | -     | -     |\n",
    "| EV/EBITDA (H/L)     | -      | -      | -     | -     | -     |\n",
    "| 영업이익률          | -      | -      | -     | -     | -     |\n",
    "| ROE                 | -      | -      | -     | -     | -     |\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/data/ephemeral/home/clone/src/modules/datas/SK케미칼_DB금융투자(2024.11.06)/SK케미칼_DB금융투자(2024.11.06).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def markdown_to_df(markdown_table: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    마크다운 테이블을 Pandas DataFrame으로 변환하는 함수\n",
    "    \n",
    "    :param markdown_table: 마크다운 형식의 테이블 문자열\n",
    "    :return: 변환된 Pandas DataFrame\n",
    "    \"\"\"\n",
    "    lines = markdown_table.strip().split(\"\\n\")\n",
    "    \n",
    "    # 헤더 추출\n",
    "    headers = [h.strip() for h in lines[0].split(\"|\") if h.strip()]\n",
    "    \n",
    "    # 데이터 행 추출 (두 번째 줄은 구분선이므로 제외)\n",
    "    data_rows = lines[2:]\n",
    "    \n",
    "    # 데이터 처리\n",
    "    data = []\n",
    "    for row in data_rows:\n",
    "        values = [v.strip() for v in row.split(\"|\") if v.strip()]\n",
    "        data.append(values)\n",
    "    \n",
    "    # 데이터프레임 생성\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/ephemeral/home/clone/src/modules/datas/SK케미칼_DB금융투자(2024.11.06)/SK케미칼_DB금융투자(2024.11.06).csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='SK하이닉스는 향후 3개년간 주주환원 정책을 공시하며, 연간 고정배당금을 1,500원으로 상향하고,  Free Cash Flow의 5% 재원을 재무 건전성 강화에 우선 활용한다고 밝혔다. 이는 메모리 업황 특성상 변동성이 큰 상황에서 내린 합리적인 결정이라고 판단된다.' metadata={'company_name': 'SK하이닉스', 'dir_route': 'datas/SK하이닉스_하나증권(2024.11.28)', 'file_name': 'SK하이닉스_하나증권(2024.11.28).pdf', 'id': 17, 'investment': '하나증권(2024.11.28)', 'original_content': 'SK하이닉스는 장 종료 후에 향후 3개년간 주주환원 쟁책을 공시했다. 기존 3개년 주주환 원 정책에서 변화가 생겼다. 변경된 부분의 핵심은 연간 고정배당금을 기존 1,200원에서 1,500원으로 상향하고, 기존 정책 하에서 지급하던 추가 배당금이었던 연간 Free Cash Flow의 5% 재원을 재무 건전성 강화에 우선 활용한다는 점이다. 아울러 정책 종료 후 총 재원 안에서 재무 건전성 목표가 달성되면 추가 환원을 실행하거나, 유의미한 수준의 Free Cash Flow 창출이 예상되는 경우에 조기 환원도 가능하다고 언급했다. 다시 설명하 자면 2025~2027년까지 3년 누적 Free Cash Flow의 50% 수준을 총 재원으로 설정하는 것은 기존과 동일하다. 다만, 기존에 매년 지급하던 FCF 내 5%의 추가 배당금을 앞으로 는 재무 건전성 강화로 사용하는 대신에 정책 종료 후 FCF 50% 수준 안에서 여유 재원을 기반으로 한 추가 환원을 결정한 것이다. 메모리 업황 특성상 변동성이 크기 때문에 예측 가능한 주주환원 규모를 선정하기 어렵기 때문에 3년 누적의 Free Cash Flow 선정은 동종 업체들의 정책과도 일맥상통하는 부분이다. 또한, SK하이닉스의 재무 건전성이 경쟁사들보 다 열위에 있던 점을 고려하면 금번 주주환원 정책 발표는 합리적인 결정이라 판단한다.', 'page': 1, 'type': 'paragraph'}\n",
      "page_content='SK하이닉스의 이번 주주환원 정책과 기업가치 제고 계획에 시장 반응은 실망스러울 수 있지만, 메모리 업종에서는 기술 리더십이 중요하며, 재무 건정성이 강화되면 중장기적으로 주주환원 강화와 연결되어 밸류에이션 할증에 대한 정당성을 확보할 수 있음을 고려해야 함' metadata={'company_name': 'SK하이닉스', 'dir_route': 'datas/SK하이닉스_하나증권(2024.11.28)', 'file_name': 'SK하이닉스_하나증권(2024.11.28).pdf', 'id': 21, 'investment': '하나증권(2024.11.28)', 'original_content': '이번에 발표된 향후 3년간 주주환원 정책과 기업가치 제고 계획에 대해 다소 실망스러운 시장 반응이 있을 수 있다. 다만, 메모리 업종은 주주환원보다 기술 리더십이 우선시 되어 야 한다. 그럼에도 불구하고 변동성 높은 업황 안에서 주주환원을 안정화시키려는 의도에 주목해야 한다는 판단이다. 글로벌 메모리 3사 중 재무 건전성 측면에서 상대적으로 열위 에 있었다는 이유로 밸류에이션 할인이 있었다는 점 또한 부인할 수 없다. 향후에 SK하이 닉스의 재무 건전성이 강화된다면, 중장기적으로 주주환원 강화와 연결될 수 있고, 나아가 밸류에이션 할증에 대한 정당성도 확보할 수 있다는 점을 고려할 필요가 있다.', 'page': 1, 'type': 'paragraph'}\n",
      "page_content='카카오뱅크는 2024년부터 26년까지 주주 환원율 50% 달성 후 27년부터 주당 배당금(DPS) 유지 또는 점진적으로 늘릴 계획이며, 이를 통해 배당 중심의 주주 환원 정책을 시행할 것으로 예상된다.' metadata={'company_name': '카카오뱅크', 'dir_route': 'datas/카카오뱅크_삼성증권(2024.11.27)', 'file_name': '카카오뱅크_삼성증권(2024.11.27).pdf', 'id': 80, 'investment': '삼성증권(2024.11.27)', 'original_content': '4. 목표: ’24~’26년 주주환원율 50% 도달 이후 ’27년부터 DPS 유지 또는 점진적 상향 – 시사점: 배당 중심 주주환원 정책 예상', 'page': 5, 'type': 'paragraph'}\n",
      "page_content='SK하이닉스는 향후 3년간 매출액 대비 CapEx 30% 중반을 목표로 하며, HBM 등 기술 리더십을 유지하면서 동시에 재무 건정성을 기반으로 한 주주환원 정책을 추진할 계획이다. 또한 안정적인 이익 창출과 재무 건전성의 강화를 바탕으로 지속적이고 균형 있는 주주환원을 계속하겠다고 밝혔다.' metadata={'company_name': 'SK하이닉스', 'dir_route': 'datas/SK하이닉스_하나증권(2024.11.28)', 'file_name': 'SK하이닉스_하나증권(2024.11.28).pdf', 'id': 19, 'investment': '하나증권(2024.11.28)', 'original_content': '주주환원과 더불어 기업가치 제고 계획도 공시했다. 3개년 이동평균 기준으로 매출액대비 CapEx 30% 중반을 목표로 하고, HBM 기반으로 기술 리더십을 유지하되, 재무 건전성을 기반으로 한 주주환원 정책을 언급했다. 매출액대비 30% 중반 수준의 CapEx는 기존에 유지하던 수익성 기반의 투자 기조와 과거보다 상향된 투자 금액을 고려한 기준이라 판단 한다. 아울러 HBM을 계기로 기술 리더십을 확보한 AI 및 차세대 메모리 기술에 있어서는 물량보다 적기 기술 확보를 핵심으로 투자할 전망이다. 마지막으로 주주환원 정책에서도 강조했던 것처럼 안정적인 이익 창출과 재무 건전성 강화를 기반으로 지속적이고 균형 있 는 주주환원을 지속할 것을 언급했다.', 'page': 1, 'type': 'paragraph'}\n",
      "page_content='카카오뱅크는 2024년에서 2025년까지 주주 환원율 50% 달성 후, 27년부터는 주당배당금(DPS)유지 또는 점진적 상승을 통한 배당 중심의 주주환원 정책을 펼칠 것으로 예상되며, 이를 위해 26년까지 높은 성장률을 이어갈 것으로 전망된다.' metadata={'id': 21, 'type': 'paragraph', 'image_route': nan, 'dir_route': 'datas/카카오뱅크_삼성증권(2024.11.27)', 'file_name': '카카오뱅크_삼성증권(2024.11.27).pdf', 'page': 1, 'investment': '삼성증권(2024.11.27)', 'company_name': '카카오뱅크', 'table': nan, 'original_content': '기업가치 제고계획 목표 4. ’24~’25년 주주환원율 50% 도달 이후 ’27년부터 DPS 유지 또 는 점진적 상향 – 배당 중심 주주환원 정책 예상: 동사의 주주환원 정책은 자사주 매입 및 소각보다는 배당 확대가 보다 현실적일 것으로 판단. 이에, DPS는 주주환원율 상향 계획에 따라 2026년까지 고성장을 지속한 후, 이익 증가 속도와 유사한 흐름을 전망.'}\n"
     ]
    }
   ],
   "source": [
    "q = 'SK하이닉스의 2024년 핵심사업에 대해 알려줘.'\n",
    "result = pipe.Q(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paragraph\n",
      "paragraph\n",
      "paragraph\n",
      "paragraph\n",
      "paragraph\n"
     ]
    }
   ],
   "source": [
    "for i in result:\n",
    "    print(i.metadata['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 참고 문서를 반드시 활용하여 질문에 대한 정확하고 간결한 답변을 작성하세요. \n",
      "답변은 반드시 질문과 관련된 사실에 기반하며, 불필요한 반복이나 모호함 없이 핵심 내용을 포함해야 합니다. \n",
      "200자를 초과하지 않도록 작성하세요.\n",
      "\n",
      "질문: SK하이닉스의 2025~2027년 주주환원 정책에서 변경된 고정배당금과 추가 배당금의 활용 방안은 무엇인가요?\n",
      "참고 문서1: SK하이닉스는 장 종료 후에 향후 3개년간 주주환원 쟁책을 공시했다. 기존 3개년 주주환 원 정책에서 변화가 생겼다. 변경된 부분의 핵심은 연간 고정배당금을 기존 1,200원에서 1,500원으로 상향하고, 기존 정책 하에서 지급하던 추가 배당금이었던 연간 Free Cash Flow의 5% 재원을 재무 건전성 강화에 우선 활용한다는 점이다. 아울러 정책 종료 후 총 재원 안에서 재무 건전성 목표가 달성되면 추가 환원을 실행하거나, 유의미한 수준의 Free Cash Flow 창출이 예상되는 경우에 조기 환원도 가능하다고 언급했다. 다시 설명하 자면 2025~2027년까지 3년 누적 Free Cash Flow의 50% 수준을 총 재원으로 설정하는 것은 기존과 동일하다. 다만, 기존에 매년 지급하던 FCF 내 5%의 추가 배당금을 앞으로 는 재무 건전성 강화로 사용하는 대신에 정책 종료 후 FCF 50% 수준 안에서 여유 재원을 기반으로 한 추가 환원을 결정한 것이다. 메모리 업황 특성상 변동성이 크기 때문에 예측 가능한 주주환원 규모를 선정하기 어렵기 때문에 3년 누적의 Free Cash Flow 선정은 동종 업체들의 정책과도 일맥상통하는 부분이다. 또한, SK하이닉스의 재무 건전성이 경쟁사들보 다 열위에 있던 점을 고려하면 금번 주주환원 정책 발표는 합리적인 결정이라 판단한다.\n",
      "참고 문서2: 이번에 발표된 향후 3년간 주주환원 정책과 기업가치 제고 계획에 대해 다소 실망스러운 시장 반응이 있을 수 있다. 다만, 메모리 업종은 주주환원보다 기술 리더십이 우선시 되어 야 한다. 그럼에도 불구하고 변동성 높은 업황 안에서 주주환원을 안정화시키려는 의도에 주목해야 한다는 판단이다. 글로벌 메모리 3사 중 재무 건전성 측면에서 상대적으로 열위 에 있었다는 이유로 밸류에이션 할인이 있었다는 점 또한 부인할 수 없다. 향후에 SK하이 닉스의 재무 건전성이 강화된다면, 중장기적으로 주주환원 강화와 연결될 수 있고, 나아가 밸류에이션 할증에 대한 정당성도 확보할 수 있다는 점을 고려할 필요가 있다.\n",
      "참고 문서3: 4. 목표: ’24~’26년 주주환원율 50% 도달 이후 ’27년부터 DPS 유지 또는 점진적 상향 – 시사점: 배당 중심 주주환원 정책 예상\n",
      "참고 문서4: 주주환원과 더불어 기업가치 제고 계획도 공시했다. 3개년 이동평균 기준으로 매출액대비 CapEx 30% 중반을 목표로 하고, HBM 기반으로 기술 리더십을 유지하되, 재무 건전성을 기반으로 한 주주환원 정책을 언급했다. 매출액대비 30% 중반 수준의 CapEx는 기존에 유지하던 수익성 기반의 투자 기조와 과거보다 상향된 투자 금액을 고려한 기준이라 판단 한다. 아울러 HBM을 계기로 기술 리더십을 확보한 AI 및 차세대 메모리 기술에 있어서는 물량보다 적기 기술 확보를 핵심으로 투자할 전망이다. 마지막으로 주주환원 정책에서도 강조했던 것처럼 안정적인 이익 창출과 재무 건전성 강화를 기반으로 지속적이고 균형 있 는 주주환원을 지속할 것을 언급했다.\n",
      "참고 문서5: 기업가치 제고계획 목표 4. ’24~’25년 주주환원율 50% 도달 이후 ’27년부터 DPS 유지 또 는 점진적 상향 – 배당 중심 주주환원 정책 예상: 동사의 주주환원 정책은 자사주 매입 및 소각보다는 배당 확대가 보다 현실적일 것으로 판단. 이에, DPS는 주주환원율 상향 계획에 따라 2026년까지 고성장을 지속한 후, 이익 증가 속도와 유사한 흐름을 전망.\"\n",
      "정답: SK하이닉스의 2025~2027년 주주환원 정책은 연간 고정배당금을 1,500원으로 상향하고, 추가 배당금은 재무 건전성 강화에 활용된다. 정책 종료 후에는 총 재원 안에서 재무 건전성 목표 달성 여부에 따라 추가 환원을 결정한다. 또한, 3년 누적 Free Cash Flow의 50%를 총 재원으로 설정하며, 유의미한 FCF 창출 시 조기 환원도 가능하다.\n",
      "</think>\n",
      "\n",
      "SK하이닉스의 2025~2027년 주주환원 정책은 연간 고정배당금을 1,500원으로 상향하고, 추가 배당금은 재무 건전성 강화에 활용된다. 정책 종료 후에는 총 재원 안에서 재무 건전성 목표 달성 여부에 따라 추가 환원을 결정한다. 또한, 3년 누적 Free Cash Flow의 50%를 총 재\n"
     ]
    }
   ],
   "source": [
    "print(answer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 DB가 있어 로드합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/clone/src/modules/DB/chromadb_storing.py:127: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  self.db = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'chrdb.db' loaded from 'modules/DB/Service_DB_NaverCloudEmb'.\n",
      "Total documents in collection 'chrdb.db': 973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'company_name': 'SK하이닉스', 'dir_route': 'datas/SK하이닉스_한화투자증권(2024.11.27)', 'file_name': 'SK하이닉스_한화투자증권(2024.11.27).pdf', 'id': 31, 'image_route': 'datas/SK하이닉스_한화투자증권(2024.11.27)/page_3_id_31_image.png', 'investment': '한화투자증권(2024.11.27)', 'page': 3, 'type': 'figure'}, page_content='SK하이닉스의 사업부별 분기 매출 비중을 나타내는 그래프입니다. DRAM, NAND, 기타 부문으로 나뉘어 있으며, DRAM 비중이 지속적으로 높은 수치를 보이고 있습니다.'),\n",
       " Document(metadata={'id': 9, 'type': 'paragraph', 'image_route': nan, 'dir_route': 'datas/CJ제일배당_메리츠증권(2024.11.19)', 'file_name': 'CJ제일배당_메리츠증권(2024.11.19).pdf', 'page': 1, 'investment': '메리츠증권(2024.11.19)', 'company_name': 'CJ제일배당', 'table': nan, 'original_content': 'CJ제일제당의 바이오 사업 매각 추진 보도. 언론 보도에 따른 예상 매각 가치는 5~6조원, 실제 매각 추진 과정에서 가치 변화는 가능하지만 매각 추진 이슈 자체 로도 긍정적인 뉴스. 지난해부터 이어진 비핵심 계열사 지상쥐(중국 식품), 셀렉타 (SPC, 농축대두단백)의 매각으로 식품, 그 중에서도 K푸드 중심으로 선택과 집중 하는 의사결정이 시작. 바이오 사업의 매각을 통해 1차적으로 재무구조가 개선되 고, 2차적으로 글로벌 식품 사업 확대를 위한 M&A로 이어진다면 밸류에이션 저평 가 요인 해소로 판단'}, page_content='CJ제일제당이 바이오 사업 매각을 추진하며 이는 5~6조원의 가치로 평가되고 있다. 이번 매각은 비핵심 계열사 정리와 K푸드 강화를 위한 결정이며 이를 통해 재무구조 개선과 글로벌 식품 사업 확대를 기대한다.'),\n",
       " Document(metadata={'company_name': 'SK하이닉스', 'dir_route': 'datas/SK하이닉스_한화투자증권(2024.11.27)', 'file_name': 'SK하이닉스_한화투자증권(2024.11.27).pdf', 'id': 19, 'image_route': 'datas/SK하이닉스_한화투자증권(2024.11.27)/page_2_id_19_image.png', 'investment': '한화투자증권(2024.11.27)', 'page': 2, 'table': '|          | 1Q24  | 2Q24  | 3Q24  | 4Q24E | 1Q25E | 2Q25E | 3Q25E | 4Q25E | 2023   | 2024E  | 2025E  |\\n|----------|-------|-------|-------|-------|-------|-------|-------|-------|--------|--------|--------|\\n| 매출액   | 12,430| 16,423| 17,573| 19,377| 17,876| 20,251| 19,536| 20,228| 32,766 | 65,803 | 77,892 |\\n|          |       |       |       |       |       |       |       |       |        |        |        |\\n| DRAM     | 7,298 | 10,463| 11,749| 13,250| 12,572| 14,313| 13,704| 14,320| 20,069 | 42,759 | 54,909 |\\n| NAND     | 4,546 | 5,340 | 5,177 | 5,426 | 4,771 | 5,373 | 5,193 | 5,197 | 10,064 | 20,488 | 20,535 |\\n| 기타     | 585   | 620   | 647   | 702   | 533   | 565   | 639   | 711   | 2,642  | 2,554  | 2,448  |\\n|          |       |       |       |       |       |       |       |       |        |        |        |\\n| QqQ(%)   | 10%   | 32%   | 7%    | 10%   | -8%   | 13%   | -4%   | 4%    | -27%   | 101%   | 18%    |\\n| /YoY(%)  |       |       |       |       |       |       |       |       |        |        |        |\\n| DRAM     | 3%    | 43%   | 12%   | 13%   | -5%   | 14%   | -4%   | 4%    | -30%   | 113%   | 28%    |\\n| NAND     | 31%   | 17%   | -3%   | 5%    | -12%  | 13%   | -3%   | 0%    | -28%   | 104%   | 0%     |\\n| 기타     | -25%  | 6%    | 4%    | 8%    | -24%  | 6%    | 13%   | 11%   | 31%    | -3%    | -4%    |\\n|          |       |       |       |       |       |       |       |       |        |        |        |\\n| 영업이익 | 2,886 | 5,469 | 7,030 | 7,882 | 6,914 | 8,103 | 7,187 | 6,846 | -7,730 | 23,266 | 29,051 |\\n|          |       |       |       |       |       |       |       |       |        |        |        |\\n| DRAM     | 2,637 | 4,694 | 6,112 | 7,108 | 6,579 | 7,680 | 6,964 | 6,938 | 968    | 20,551 | 28,161 |\\n| NAND     | 281   | 811   | 950   | 808   | 362   | 452   | 255   | -56   | -8,551 | 2,851  | 1,012  |\\n| 기타     | -32   | -36   | -32   | -35   | -27   | -28   | -32   | -36   | -149   | -136   | -72    |\\n|          |       |       |       |       |       |       |       |       |        |        |        |\\n| OPM(%)   | 23%   | 33%   | 40%   | 41%   | 39%   | 40%   | 37%   | 34%   | -24%   | 35%    | 37%    |\\n|          |       |       |       |       |       |       |       |       |        |        |        |\\n| DRAM     | 36%   | 45%   | 52%   | 54%   | 52%   | 54%   | 51%   | 48%   | 5%     | 48%    | 51%    |\\n| NAND     | 6%    | 15%   | 18%   | 15%   | 8%    | 8%    | 5%    | -1%   | -85%   | 14%    | 5%     |\\n|          |       |       |       |       |       |       |       |       |        |        |        |\\n| 주요가정 | DRAM B/G| -15% | 21%   | -1%   | 7%    | -6%   | 15%   | 2%    | 10%    | 14%    | 18%    | 19%    |\\n|          | DRAM ASP| 22%   | 15%   | 14%   | 5%    | 2%    | -1%   | -4%   | -5%   | -40%   | 75%    | 10%    |\\n|          | NAND B/G| 0%    | -2%   | -14%  | 12%   | -3%   | 15%   | 4%    | 11%    | 27%    | 4%     | 13%    |\\n|          | NAND ASP| 31%   | 16%   | 13%   | -7%   | -8%   | -2%   | -5%    | -10%   | -45%   | 90%    | -10%    |', 'type': 'table'}, page_content='SK하이닉스의 실적 추이를 나타내는 테이블로, 매출액, 영업이익, OPM, 주요가정 등을 분기별 및 연도별로 정리하고 있습니다.'),\n",
       " Document(metadata={'id': 18, 'type': 'list', 'image_route': nan, 'dir_route': 'datas/SK케미칼_DB금융투자(2024.11.06)', 'file_name': 'SK케미칼_DB금융투자(2024.11.06).pdf', 'page': 3, 'investment': 'DB금융투자(2024.11.06)', 'company_name': 'SK케미칼', 'table': nan, 'original_content': '▪ 자료 발간일 현재 본 자료를 작성한 조사분석담당자와 그 배우자는 해당종목과 재산적 이해관계가 없습니다. ▪ 당사는 자료 발간일 현재 지난 1년간 위 조사분석자료에 언급한 종목들의 IPO 대표주관업무를 수행한 사실이 없습니다. ▪ 당사는 자료 발간일 현재 위 조사분석자료에 언급된 종목의 지분을 1%이상 보유하고 있지 않습니다. ▪ 당사는 자료 발간일 현재 조사분석자료에 언급된 법인과 “독점규제 및 공정거래에 관한 법률” 제2조 제3호에 따른 계열회사의 관계에 있지 않습니다. ▪ 동 자료내용은 기관투자가 등 제 3자에게 사전 제공된 사실이 없습니다. ▪ 이 자료에 게재된 내용들은 본인의 의견을 정확하게 반영하고 있으며, 외부의 부당한 압력이나 간섭없이 작성되었음을 확인합니다. ▪ 본 조사자료는 고객의 투자참고용으로 작성된 것이며, 당사의 리서치센터가 신뢰할 수 있는 자료 및 정보로부터 얻어진 것이나 당사가 그 정확성이나 완전성을 보장할 수 없으므로 어떠한 경우에도 고객의 증권투자결과에 대한 법적 책임소재의 증빙자료로 사용될 수 없습니다. 본 조사자료는 당사의 허락없이 무단 복제 및 배포할 수 없습니다. ▪ 발행주식수 변동 시 목표주가와 괴리율은 수정주가를 기준으로 산출하였습니다.'}, page_content='SK케미칼 관련 분석 자료에서는 주식보유현황, 기업과의 관계, 자료의 투명성 등을 명시하며, 어떠한 경우에도 고객의 증권투자 결과에 대한 법적 책임 소재의 증빙 자료로 사용될 수 없음을 알린다.'),\n",
       " Document(metadata={'company_name': 'SK하이닉스', 'dir_route': 'datas/SK하이닉스_교보증권(2024.10.25)', 'file_name': 'SK하이닉스_교보증권(2024.10.25).pdf', 'id': 23, 'image_route': 'datas/SK하이닉스_교보증권(2024.10.25)/page_2_id_23_image.png', 'investment': '교보증권(2024.10.25)', 'page': 2, 'table': '| 구분       | 1Q23     | 2Q23     | 3Q23     | 4Q23     | 1Q24     | 2Q24     | 3Q24     | 4Q24F    | 2023      | 2024F     | 2025F     |\\n|------------|----------|----------|----------|----------|----------|----------|----------|----------|-----------|-----------|-----------|\\n| 매출액     | 5,088.1  | 7,459.2  | 9,066.2  | 11,305.5 | 12,429.6 | 16,423.0 | 17,573.0 | 19,893.0 | 32,919.0  | 65,502.0  | 92,602.1  |\\n| % QoQ      | -33.7%   | 46.6%    | 21.5%    | 24.7%    | 9.9%     | 32.1%    | 7.0%     | 13.2%    | -26.2%    | 99.0%     | 41.4%     |\\n| % YoY      | -58.1%   | -46.0%   | -17.5%   | 47.4%    | 144.3%   | 120.2%   | 93.8%    | 76.0%    | -26.2%    | 99.0%     | 41.4%     |\\n| DRAM       | 3,187.6  | 4,951.0  | 6,649.7  | 7,926.2  | 7,996.9  | 11,321.2 | 12,848.5 | 14,286.2 | 22,714.4  | 46,452.8  | 67,534.9  |\\n| NAND       | 1,708.8  | 2,362.4  | 2,454.1  | 3,495.2  | 4,563.2  | 5,276.9  | 4,993.0  | 5,763.9  | 10,020.6  | 20,597.1  | 27,041.4  |\\n| 영업이익   | -3,402.0 | -3,250.7 | -1,791.0 | 346.0    | 2,886.0  | 5,750.4  | 7,030.0  | 8,315.0  | -8,097.7  | 23,981.4  | 39,623.9  |\\n| % QoQ      | 적지     | 적지     | 적지     | 흑전     | 734.1%   | 99.3%    | 22.3%    | 18.3%    | 적전      | 흑전      | 흑전      |\\n| % YoY      | 적전     | 적전     | 적전     | 흑전     | 흑전     | 흑전     | 흑전     | 흑전     | 적전      | 흑전      | 흑전      |\\n| DRAM       | -1,115.7 | -495.1   | 59.8     | 1,561.5  | 2,423.1  | 5,037.9  | 6,681.2  | 7,714.5  | 10.5      | 21,856.7  | 35,007.4  |\\n| NAND       | -2,158.2 | -2,692.5 | -2,454.1 | -1,048.6 | 625.2    | 738.8    | 858.8    | 876.1    | -8,353.4  | 3,098.8   | 5,415.9   |\\n| 영업이익률 | -66.9%   | -43.6%   | -19.8%   | 3.1%     | 23.2%    | 35.0%    | 40.0%    | 41.8%    | -24.6%    | 36.6%     | 42.8%     |\\n| DRAM       | -35.0%   | -10.0%   | 0.9%     | 19.7%    | 30.3%    | 44.5%    | 52.0%    | 54.0%    | 0.0%      | 47.1%     | 51.8%     |\\n| NAND       | -126.3%  | -114.0%  | -100.0%  | -30.0%   | 13.7%    | 14.0%    | 17.2%    | 15.2%    | -83.4%    | 15.0%     | 20.0%     |', 'type': 'table'}, page_content='SK하이닉스의 부문별 매출, 영업이익 및 영업이익률의 추세와 전망을 나타내는 테이블입니다.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "project_root = os.getcwd()\n",
    "sys.path.append(project_root + '/modules')\n",
    "from Pipeline import pipe_service\n",
    "\n",
    "pipe = pipe_service()\n",
    "pipe.Q('SK하이닉스의 핵심사업에 대해 알려줘.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
